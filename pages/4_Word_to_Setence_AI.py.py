from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_groq import ChatGroq
import streamlit as st
import os
import pandas as pd
import random
from groq import Groq

# Streamlit í˜ì´ì§€ íƒ€ì´í‹€ ì„¤ì •
st.title("ğŸ¦œğŸ”— Word to Sentence")

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
groq_api_key = st.secrets["GROQ_API_KEY"]

# Groq Langchain ì±— ê°ì²´ ì´ˆê¸°í™”
groq_chat = ChatGroq(api_key=groq_api_key, model_name="gemma-7b-it")

# ëŒ€í™” ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferWindowMemory(k=5)

# ëŒ€í™” ì²´ì¸ ì„¤ì •
conversation = ConversationChain(
    llm=groq_chat,
    memory=memory
)

# íŒŒì¼ ì—…ë¡œë” ì„¤ì •
def load_words():
    file_name = 'http://ewking.kr/AE/word_sentence.xlsx'
    if file_name.endswith('.csv'):
        df = pd.read_csv(file_name)
    elif file_name.endswith('.xlsx') or file_name.endswith('.xls'):
        df = pd.read_excel(file_name)
    words_column = 'words'
    if df is not None and words_column in df.columns:
        st.session_state['ai_words_list'] = df[words_column].dropna().tolist()
        random.shuffle(st.session_state['ai_words_list'])

def generate_sentence_with_word(word):
    try:
        client = Groq(api_key=groq_api_key)
        completion = client.chat.completions.create(
            model="gemma-7b-it",
            messages=[
                {
                    "role": "system",
                    "content": "When an English word is provided, you need to create one simple and easy English conversation sentence that is commonly used in everyday life using the word '{}'. You also need to provide one Korean translation of the English conversation sentence you created. In this way, you should provide a total of only two sentences.".format(word)
                },
                {
                    "role": "user",
                    "content": "Create a sentence using '{}'.".format(word)
                }
            ],
            temperature=0,
            max_tokens=1024,
            top_p=0,
            stream=False
        )
        response = completion.choices[0].message.content
        # ì‘ë‹µ íŒŒì‹±
        lines = response.split('\n')
        english_sentence, korean_translation = None, None
        for line in lines:
            cleaned_line = line.strip().strip('"')
            if '**English:**' in cleaned_line:
                english_sentence = cleaned_line.replace('**English:**', '').strip().strip('"')
                english_sentence = english_sentence.replace('**', '')  # '**' ì œê±°
            elif '**Korean:**' in cleaned_line:
                korean_translation = cleaned_line.replace('**Korean:**', '').strip().strip('"')
                korean_translation = korean_translation.replace('**', '')  # '**' ì œê±°

        if english_sentence and korean_translation:
            return english_sentence, korean_translation
        else:
            raise ValueError("Response does not contain expected format of English and Korean sentences.")
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

if st.session_state['start'] and st.session_state.get('ai_words_list'):
    random_word = st.session_state['ai_words_list'].pop(0)
    st.session_state['ai_learned_count'] += 1  # í•™ìŠµí•œ ë‹¨ì–´ ì¹´ìš´íŠ¸ ì¦ê°€
    with st.spinner('ë¬¸ì¥ ìƒì„±ì¤‘...'):
        english_sentence, korean_translation = generate_sentence_with_word(random_word)
        if english_sentence and korean_translation:
            highlighted_english_sentence = english_sentence.replace(random_word, f'<strong>{random_word}</strong>')
            st.markdown(f'<p style="font-size: 20px; text-align: center;">{highlighted_english_sentence}</p>', unsafe_allow_html=True)
            st.markdown(f'<p style="font-size: 20px; text-align: center;">{korean_translation}</p>', unsafe_allow_html=True)
            st.markdown(f'ê³µë¶€í•œ ë‹¨ì–´ ìˆ˜: {st.session_state["ai_learned_count"]}')  # í•™ìŠµí•œ ë‹¨ì–´ ìˆ˜ í‘œì‹œ

    if st.button('ë‹¤ìŒ ë‹¨ì–´') or not st.session_state.get('ai_words_list'):
        if not st.session_state['ai_words_list']:
            st.markdown(f'<p style="background-color: #bffff2; padding: 10px;">ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•œ ë¬¸ì¥ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.<br>ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ ë‹¤ì‹œì‹œì‘ ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”.</p>', unsafe_allow_html=True)
            st.session_state['start'] = False
            st.session_state['ai_words_list'] = []
            st.session_state['ai_learned_count'] = 0
            load_words()  # ë‹¤ì‹œ ì‹œì‘í•˜ë ¤ë©´ ë‹¨ì–´ ëª©ë¡ì„ ë‹¤ì‹œ ë¡œë“œ
            st.session_state['start'] = True
