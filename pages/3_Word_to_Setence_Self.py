import streamlit as st
import pandas as pd
from groq import Groq

# ìŠ¤íŠ¸ë¦¼ë¦¿ í˜ì´ì§€ ì„¤ì •
st.title("ğŸ¦œğŸ”— Word to Sentence")

# Groq API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = Groq()

def load_file(uploaded_file):
    if uploaded_file.name.endswith('.csv'):
        return pd.read_csv(uploaded_file)
    elif uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
        return pd.read_excel(uploaded_file)

def generate_sentence_with_word(word):
    try:
        completion = client.chat.completions.create(
            model="llama3-70b-8192",
            messages=[
                {
                    "role": "system",
                    "content": "When an English word is provided, you need to create one simple and easy English conversation sentence that is commonly used in everyday life. You also need to provide one Korean translation of the English conversation sentence you created."
                },
                {
                    "role": "user",
                    "content": word
                }
            ],
            temperature=0,
            max_tokens=1024,
            top_p=0,
            stream=False
        )
        response = completion.choices[0].text  # ìˆ˜ì •ëœ ë¶€ë¶„: 'delta' ëŒ€ì‹  'text' ì‚¬ìš©
        english_sentence, korean_translation = response.strip().split('\n')
        return english_sentence, korean_translation
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

uploaded_file = st.file_uploader("Choose a file", type=["csv", "xlsx", "xls"])

if uploaded_file is not None:
    if 'words_list' not in st.session_state or st.button("Restart"):
        df = load_file(uploaded_file)
        words_column = 'words'
        if df is not None and words_column in df.columns:
            st.session_state['words_list'] = df[words_column].dropna().tolist()
            st.session_state['learned_count'] = 0

    if st.session_state.get('words_list'):
        word = st.session_state['words_list'].pop(0)
        st.session_state['learned_count'] += 1
        with st.spinner('ë¬¸ì¥ ìƒì„±ì¤‘...'):
            english_sentence, korean_translation = generate_sentence_with_word(word)
            if english_sentence and korean_translation:
                st.markdown(f'<p style="font-size: 20px; text-align: center;">{english_sentence}</p>', unsafe_allow_html=True)
                st.markdown(f'<p style="font-size: 20px; text-align: center;">{korean_translation}</p>', unsafe_allow_html=True)
                st.markdown(f'ê³µë¶€í•œ ë‹¨ì–´ ìˆ˜: {st.session_state["learned_count"]}')

        if not st.session_state['words_list']:
            st.markdown('<p style="background-color: #bffff2; padding: 10px;">ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•œ ë¬¸ì¥ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.</p>', unsafe_allow_html=True)
            del st.session_state['words_list']
            st.session_state['learned_count'] = 0  # í•™ìŠµ ì¹´ìš´í„° ì´ˆê¸°í™”
