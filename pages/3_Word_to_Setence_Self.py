from langchain.chains import ConversationChain
from langchain.chains.conversation.memory import ConversationBufferWindowMemory
from langchain_groq import ChatGroq
import streamlit as st
import os
import pandas as pd
import random

# Streamlit í˜ì´ì§€ íƒ€ì´í‹€ ì„¤ì •
st.title("ğŸ¦œğŸ”— Word to Sentence")

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
groq_api_key = st.secrets["GROQ_API_KEY"]

# Groq Langchain ì±— ê°ì²´ ì´ˆê¸°í™”
groq_chat = ChatGroq(api_key=groq_api_key, model_name="llama3-70b-8192")

# ëŒ€í™” ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferWindowMemory(k=5)

# ëŒ€í™” ì²´ì¸ ì„¤ì •
conversation = ConversationChain(
    llm=groq_chat,
    memory=memory
)

# íŒŒì¼ ì—…ë¡œë” ì„¤ì •
uploaded_file = st.file_uploader("Choose a file", type=["csv", "xlsx", "xls"])

if uploaded_file is not None:
    if st.button("Restart"):
        if 'words_list' in st.session_state:
            st.session_state.pop('words_list')

if 'words_list' not in st.session_state:
    st.session_state['words_list'] = []
    st.session_state['learned_count'] = 0  # í•™ìŠµ ì¹´ìš´í„°ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€

if uploaded_file is not None and not st.session_state['words_list']:
    def load_file(uploaded_file):
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
            return pd.read_excel(uploaded_file)

    df = load_file(uploaded_file)
    words_column = 'words'
    if df is not None and words_column in df.columns:
        st.session_state['words_list'] = df[words_column].dropna().tolist()
        random.shuffle(st.session_state['words_list'])

def generate_sentence_with_word(word):
    try:
        # AIì—ê²Œ ì˜ì–´ ë¬¸ì¥ê³¼ í•œêµ­ì–´ ë²ˆì—­ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­
        response = conversation(f"Please generate a simple English sentence using the word '{word}', and provide a Korean translation.")
        if 'responses' in response:
            english_sentence = response['responses'][0]['english']
            korean_translation = response['responses'][0]['korean']
        else:
            raise ValueError("No valid response from AI.")

        return english_sentence, korean_translation
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

if st.session_state.get('words_list'):
    random_word = st.session_state['words_list'].pop(0)
    st.session_state['learned_count'] += 1
    with st.spinner('ë¬¸ì¥ ìƒì„± ì¤‘...'):
        english_sentence, korean_translation = generate_sentence_with_word(random_word)
        if english_sentence and korean_translation:
            highlighted_english_sentence = english_sentence.replace(random_word, f'<strong>{random_word}</strong>')
            st.markdown(f'<p style="font-size: 20px; text-align: center;">{highlighted_english_sentence}</p>', unsafe_allow_html=True)
            st.markdown(f'<p style="font-size: 20px; text-align: center;">{korean_translation}</p>', unsafe_allow_html=True)
            st.markdown(f'ê³µë¶€í•œ ë‹¨ì–´ ìˆ˜: {st.session_state["learned_count"]}')

if uploaded_file is not None and 'words_list' in st.session_state:
    if st.button("ë‹¤ìŒ ë‹¨ì–´"):
        if not st.session_state['words_list']:
            st.markdown(f'<p style="background-color: #bffff2; padding: 10px;">ëª¨ë“  ë‹¨ì–´ì— ëŒ€í•œ ë¬¸ì¥ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.</p>', unsafe_allow_html=True)
            del st.session_state['words_list']
            st.session_state['learned_count'] = 0  # í•™ìŠµ ì¹´ìš´í„° ì´ˆê¸°í™”
